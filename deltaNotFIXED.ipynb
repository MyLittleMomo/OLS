{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-mWJy7-6VoI",
        "outputId": "5dd24f18-6027-460f-9c7d-fc4a0e059cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9814060000000008\n"
          ]
        }
      ],
      "source": [
        "#Compilation takes approximately 14 minutes (Code was compiled 20 times)\n",
        "from sklearn import random\n",
        "from sklearn import datasets\n",
        "import math\n",
        "import numpy as np\n",
        "from sklearn import linear_model\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn import linear_model\n",
        "LST= [None]*1000;\n",
        "delta=0.05; #you can vary the delta in the interval (0,1]. I started with the value 0.05 and was increasing it by 0.05 after each time i run the code\n",
        "MEAN=0; \n",
        "SUM=0; \n",
        "for q in range(0,1000): #1000 times \n",
        "  for k in range(0,1000): #1000 datasets for each q \n",
        "    m=17 #fixed training sample size, not so big and so small in order to have better result\n",
        "    d=2 #fixed number of features\n",
        "    x,y, coef=datasets.make_regression(n_samples=20, n_features=2, n_informative=2, noise=10, coef=True)\n",
        "    x=np.interp(x,(x.min(),x.max()), (0,50)) #data scaled\n",
        "    y=np.interp(y, (y.min(), y.max()),(1000,2000)) #data scaled\n",
        "    x_train= x[:m,-d:]\n",
        "    y_train= y[:m]\n",
        "    x_test= x[-3:,-d:]\n",
        "    y_test= y[-3:]\n",
        "    model = linear_model.LinearRegression(fit_intercept=False)\n",
        "    model.fit(x_train, y_train)\n",
        "    #print('Coefs: \\n', model.coef_)\n",
        "    y_pred =model.predict(x_test)\n",
        "    #print(\"Mean squared error: %.2f\" % mean_squared_error(y_test,y_pred))\n",
        "    RH = mean_squared_error(y_test, y_pred)\n",
        "    #print(\"Real error RH = \",RH)\n",
        "    w_star=model.coef_\n",
        "    #print(w_star)\n",
        "    L=[None]*(len(x_train));\n",
        "    for i in range(0,len(x_train)):\n",
        "      L[i]=(abs(np.dot(w_star, x_train[i])-y_train[i]))*(abs(np.dot(w_star, x_train[i])-y_train[i]))\n",
        "      #print(\"Error on training point \",i+1,\" = \",L[i])\n",
        "    M=max(L);\n",
        "    #print('Loss function bound M =',M)\n",
        "    LH=0;\n",
        "    for j in range(0,len(x_train)):\n",
        "      LH=LH+L[j];\n",
        "    RS=abs(LH/len(x_train));\n",
        "    #print('Empirical risk RS = ',RS);\n",
        "    ErrorBound=RS+M*math.sqrt((2*d*math.log(math.e*m/d))/m) +M*math.sqrt((math.log(1/delta))/(2*m))\n",
        "    #print('Error bound = ',ErrorBound);\n",
        "    TEST=ErrorBound-RH;\n",
        "      #print(TEST);\n",
        "    if (TEST>=0): \n",
        "      LST[k]=1;\n",
        "    else:\n",
        "      LST[k]=-1;\n",
        "  PN=0;\n",
        "  for o in range(0,1000):\n",
        "    if (LST[o]>=0):\n",
        "      PN=PN+1;\n",
        "  #print(PN)\n",
        "  Probability=PN/len(LST);\n",
        "  #print(Probability)\n",
        "  SUM=SUM+Probability;\n",
        "MEAN=SUM/1000; #Average probability of Error bound formula working given the delta\n",
        "print(MEAN); "
      ]
    }
  ]
}